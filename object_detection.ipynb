{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "object_detection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEn70VELAM_l"
      },
      "source": [
        "##Object detection with YOLOv5\n",
        "- Firts attempt to fine tune YOLOv5 according to this tutorial:\n",
        "https://curiousily.com/posts/object-detection-on-custom-dataset-with-yolo-v5-using-pytorch-and-python/\n",
        "- Dataset we added bounding boxes to: https://www.kaggle.com/moltean/fruits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOuGWLxGAFnI"
      },
      "source": [
        "\n",
        "import os\n",
        "import sys\n",
        "import torch\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "import PIL.Image as Image\n",
        "import cv2\n",
        "import pathlib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pathlib import Path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqalL1RW_wA0"
      },
      "source": [
        "PATH_TO_DATA = \"/content/gdrive/MyDrive/fruits-360_dataset/\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNA2ZUlHRZBn",
        "outputId": "a458b0f0-3ece-4f6a-acdd-9551844d079f"
      },
      "source": [
        "# mount google drive \n",
        "drive.mount('/content/gdrive')\n",
        "sys.path.append(PATH_TO_DATA)\n",
        "# change current working directory to /0db, where are Tokenizer module is \n",
        "%cd \"/content/gdrive/MyDrive/fruits-360_dataset/\"\n",
        "%ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/MyDrive/fruits-360_dataset\n",
            "\u001b[0m\u001b[01;34mdatasets\u001b[0m/  \u001b[01;34mtest\u001b[0m/  \u001b[01;34mtrain\u001b[0m/  \u001b[01;34myolov5\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cLm5VjIqE8S"
      },
      "source": [
        "def resize(image_path):\n",
        "  # read image shape \n",
        "  img = cv2.imread(image_path)\n",
        "  height, width, channels = img.shape   \n",
        "  img = cv2.rectangle(\n",
        "      img,\n",
        "      (int(0), int(0)),\n",
        "      (int(width-5), int(height-5)),\n",
        "      color=(0, 255, 0),\n",
        "      thickness=2\n",
        "    )\n",
        "  cv2.imwrite(image_path, img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVXh8pM9R7ij"
      },
      "source": [
        "# add some bounding boxes to the data\n",
        "path = PATH_TO_DATA\n",
        "i = 0\n",
        "\n",
        "train_files = []\n",
        "train_labels = []\n",
        "test_files = []\n",
        "test_labels = []\n",
        "#keeps track of the available classes\n",
        "categories = []\n",
        "\n",
        "# subsets are train and test data\n",
        "for subset in os.listdir(path):\n",
        "    if subset == 'train':\n",
        "      path = os.path.join(path, subset)\n",
        "      for category in os.listdir(path):\n",
        "        category_path = os.path.join(path, category)\n",
        "        categories.append(category)\n",
        "        \n",
        "        for filename in os.listdir(category_path):\n",
        "          if filename.endswith(\".jpg\"):\n",
        "            image_path = os.path.join(category_path, filename)\n",
        "            # maybe add resizing step??\n",
        "            resize(image_path)\n",
        "            train_files.append(image_path)\n",
        "            train_labels.append(category)\n",
        "            print(image_path)\n",
        "            \n",
        "            i = i+1\n",
        "            print(i)\n",
        "    else:\n",
        "       path = os.path.join(path, subset)\n",
        "       for category in os.listdir(path):\n",
        "          category_path = os.path.join(path, category)\n",
        "          \n",
        "          for filename in os.listdir(category_path):\n",
        "            if filename.endswith(\".jpg\"):\n",
        "              image_path = os.path.join(category_path, filename)\n",
        "              # maybe add resizing step??\n",
        "              print(image_path)\n",
        "              resize(image_path)\n",
        "              test_files.append(image_path)\n",
        "              test_labels.append(category)\n",
        "              i = i+1\n",
        "              print(i)\n",
        "      \n",
        "    path = PATH_TO_DATA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32lloMoQQQMf",
        "outputId": "22bfe4bb-bebb-4a6e-8393-d1527b3d4eb4"
      },
      "source": [
        "# test if number of classes were stored correctly \n",
        "print(categories)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Apple Red 1', 'Banana', 'Orange', 'Avocado', 'Kiwi', 'Strawberry', 'Peach', 'Tomato 1', 'Potato Red', 'Apricot']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JtQ-OyF8Z29"
      },
      "source": [
        "\n",
        "def create_dataset(files, categories, dataset_type):\n",
        "  \n",
        "  images_path = Path(f\"/content/gdrive/MyDrive/fruit/images/{dataset_type}\")\n",
        "  images_path.mkdir(parents=True, exist_ok=True)\n",
        "  labels_path = Path(f\"/content/gdrive/MyDrive/fruit/labels/{dataset_type}\")\n",
        "  labels_path.mkdir(parents=True, exist_ok=True)\n",
        "  \n",
        "  for single_file in files:\n",
        "    \n",
        "    #save image in new path to ensure compliance with darknet format\n",
        "    old_image_path = pathlib.PurePath(single_file)     \n",
        "    img = Image.open(single_file)\n",
        "    img = img.convert(\"RGB\")\n",
        "    image_name = os.path.basename(single_file)\n",
        "\n",
        "    img.save(str(images_path / image_name))\n",
        "    \n",
        "    # create files for labels according to darknet format\n",
        "    label_name = f\"{image_name.replace('.jpg', '')}.txt\"\n",
        "    \n",
        "    with (labels_path / label_name).open(mode=\"w\") as label_file:\n",
        "      \n",
        "      category_idx = categories.index(old_image_path.parent.name)      \n",
        "      img = cv2.imread(single_file)\n",
        "      height, width, channels = img.shape\n",
        "      x1, y1 = 0, 0\n",
        "      x2, y2 = width, height\n",
        "      bbox_width = x2 - x1\n",
        "      bbox_height = y2 - y1\n",
        "      label_file.write(\n",
        "            f\"{category_idx} {x1 + bbox_width / 2} {y1 + bbox_height / 2} {bbox_width} {bbox_height}\\n\"\n",
        "          )\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oc5qPKhNN194"
      },
      "source": [
        "# split original train set to train and val set\n",
        "\n",
        "train_fruit, val_fruit = train_test_split(train_files, test_size=0.1)\n",
        "\n",
        "\n",
        "# create folders with train and val datasets\n",
        "create_dataset(train_fruit, categories, 'train')\n",
        "create_dataset(val_fruit, categories, 'val')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgQ0rYBVWphR"
      },
      "source": [
        "# import YOLO5\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "%pip install -r requirements.txt\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8H--9dLqhrY0"
      },
      "source": [
        "# fine tune model on our own dataset\n",
        "!python train.py --img 640 --batch 4 --epochs 30 \\\n",
        "  --data ./data/fruit.yaml --cfg ./models/yolov5x.yaml --weights yolov5x.pt \\\n",
        "  --name yolov5x_fruit --cache"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}